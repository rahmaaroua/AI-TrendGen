{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T12:44:16.264940Z",
     "iopub.status.busy": "2025-02-12T12:44:16.264630Z",
     "iopub.status.idle": "2025-02-12T12:44:29.508946Z",
     "shell.execute_reply": "2025-02-12T12:44:29.507727Z",
     "shell.execute_reply.started": "2025-02-12T12:44:16.264911Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install webdriver-manager\n",
    "!pip install selenium pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T12:45:29.356379Z",
     "iopub.status.busy": "2025-02-12T12:45:29.355988Z",
     "iopub.status.idle": "2025-02-12T12:45:29.989315Z",
     "shell.execute_reply": "2025-02-12T12:45:29.987964Z",
     "shell.execute_reply.started": "2025-02-12T12:45:29.356347Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import time\n",
    "from pprint import pprint\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T12:45:31.952437Z",
     "iopub.status.busy": "2025-02-12T12:45:31.951884Z",
     "iopub.status.idle": "2025-02-12T12:45:31.963698Z",
     "shell.execute_reply": "2025-02-12T12:45:31.962266Z",
     "shell.execute_reply.started": "2025-02-12T12:45:31.952403Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# def fetch_tweets(query, max_tweets=10, max_scrolls=50):\n",
    "#     # Initialize the WebDriver\n",
    "#     options = webdriver.ChromeOptions()\n",
    "#     options.add_argument(\"--headless\")  # Run in headless mode\n",
    "#     options.add_argument(\"--disable-gpu\")  # Disable GPU acceleration\n",
    "#     options.add_argument(\"--no-sandbox\")\n",
    "#     options.add_argument(\"--disable-dev-shm-usage\")\n",
    "#     options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.51 Safari/537.36\")\n",
    "\n",
    "#     driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=options)\n",
    "#     driver.implicitly_wait(10)  # Implicit wait for elements to load\n",
    "\n",
    "#     # Open Twitter/X search page\n",
    "#     url = f'https://x.com/search?q=\"{query}\"&src=typed_query'\n",
    "#     print(f\"Opening URL: {url}\")\n",
    "#     driver.get(url)\n",
    "\n",
    "#     tweets_list = []\n",
    "#     tweet_count = 0\n",
    "#     scroll_count = 0\n",
    "\n",
    "#     try:\n",
    "#         while tweet_count < max_tweets and scroll_count < max_scrolls:\n",
    "            \n",
    "#             # **Scroll down**\n",
    "#             driver.find_element(By.TAG_NAME, 'body').send_keys(Keys.END)\n",
    "#             time.sleep(random.uniform(2, 5))  # Wait 2-5 seconds after scrolling\n",
    "            \n",
    "#             # Wait for tweets to load\n",
    "#             WebDriverWait(driver, 10).until(\n",
    "#                 EC.presence_of_all_elements_located((By.XPATH, '//article[@data-testid=\"tweet\"]'))\n",
    "#             )\n",
    "\n",
    "#             tweets = driver.find_elements(By.XPATH, '//article[@data-testid=\"tweet\"]')\n",
    "            \n",
    "#             if not tweets:\n",
    "#                 print(\"No tweets found, trying again...\")\n",
    "#                 continue\n",
    "            \n",
    "#             print(f\"Found {len(tweets)} tweets on the page.\")\n",
    "\n",
    "#             for tweet in tweets:\n",
    "#                 if tweet_count >= max_tweets:\n",
    "#                     break\n",
    "\n",
    "#                 try:\n",
    "#                     content_element = tweet.find_element(By.XPATH, './/div[@lang]')  # Main tweet text\n",
    "#                     datetime_element = tweet.find_element(By.XPATH, './/time')\n",
    "#                     user_name_element = tweet.find_element(By.XPATH, './/div[@dir=\"ltr\"]/span')\n",
    "#                     retweets_element = tweet.find_element(By.XPATH, './/div[@data-testid=\"retweet\"]')\n",
    "#                     likes_element = tweet.find_element(By.XPATH, './/div[@data-testid=\"like\"]')\n",
    "\n",
    "#                     content = content_element.text if content_element else \"N/A\"\n",
    "#                     datetime = datetime_element.get_attribute('datetime') if datetime_element else \"N/A\"\n",
    "#                     user_name = user_name_element.text if user_name_element else \"N/A\"\n",
    "#                     retweets = retweets_element.text if retweets_element else \"0\"\n",
    "#                     likes = likes_element.text if likes_element else \"0\"\n",
    "\n",
    "#                     tweets_list.append({\n",
    "#                         'datetime': datetime,\n",
    "#                         'user_name': user_name,\n",
    "#                         'content': content,\n",
    "#                         'retweets': retweets,\n",
    "#                         'likes': likes\n",
    "#                     })\n",
    "\n",
    "#                     tweet_count += 1\n",
    "#                     print(f\"Scraped {tweet_count}/{max_tweets} tweets.\")\n",
    "\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Error parsing tweet: {e}\")\n",
    "\n",
    "#             # Scroll down to load more tweets\n",
    "#             driver.find_element(By.TAG_NAME, 'body').send_keys(Keys.END)\n",
    "#             time.sleep(2)  # Wait for new tweets to load\n",
    "#             scroll_count += 1\n",
    "#             print(f\"Scrolled {scroll_count}/{max_scrolls} times.\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error during fetching tweets: {e}\")\n",
    "#     finally:\n",
    "#         driver.quit()\n",
    "\n",
    "#     return tweets_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Using cached selenium-4.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\jojo\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.3)\n",
      "Collecting trio~=0.17 (from selenium)\n",
      "  Using cached trio-0.28.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium)\n",
      "  Using cached trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\jojo\\anaconda3\\lib\\site-packages (from selenium) (2025.1.31)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\jojo\\anaconda3\\lib\\site-packages (from selenium) (4.11.0)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\jojo\\anaconda3\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Collecting attrs>=23.2.0 (from trio~=0.17->selenium)\n",
      "  Using cached attrs-25.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\jojo\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\jojo\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.7)\n",
      "Collecting outcome (from trio~=0.17->selenium)\n",
      "  Using cached outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\jojo\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\jojo\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.17.1)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
      "  Using cached wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\jojo\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\jojo\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\jojo\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Using cached selenium-4.28.1-py3-none-any.whl (9.5 MB)\n",
      "Using cached trio-0.28.0-py3-none-any.whl (486 kB)\n",
      "Using cached trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Using cached attrs-25.1.0-py3-none-any.whl (63 kB)\n",
      "Using cached wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Using cached outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Installing collected packages: wsproto, attrs, outcome, trio, trio-websocket, selenium\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 23.1.0\n",
      "    Uninstalling attrs-23.1.0:\n",
      "      Successfully uninstalled attrs-23.1.0\n",
      "Successfully installed attrs-25.1.0 outcome-1.3.0.post0 selenium-4.28.1 trio-0.28.0 trio-websocket-0.11.1 wsproto-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting webdriver-manager\n",
      "  Using cached webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\jojo\\anaconda3\\lib\\site-packages (from webdriver-manager) (2.32.3)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\jojo\\anaconda3\\lib\\site-packages (from webdriver-manager) (0.21.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\jojo\\anaconda3\\lib\\site-packages (from webdriver-manager) (24.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jojo\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jojo\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jojo\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jojo\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2025.1.31)\n",
      "Using cached webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
      "Installing collected packages: webdriver-manager\n",
      "Successfully installed webdriver-manager-4.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cookies loaded successfully!\n",
      "Current page title: \n",
      "Final Cookies in Browser: [{'domain': '.x.com', 'expiry': 1770913041, 'httpOnly': False, 'name': 'twid', 'path': '/', 'sameSite': 'None', 'secure': True, 'value': 'u%3D1825171960537513984'}, {'domain': 'x.com', 'httpOnly': False, 'name': 'lang', 'path': '/', 'sameSite': 'Lax', 'secure': False, 'value': 'en'}, {'domain': '.x.com', 'expiry': 1773924258, 'httpOnly': False, 'name': 'ct0', 'path': '/', 'sameSite': 'Lax', 'secure': True, 'value': 'f86986a4ce28c953c89d10767b9e39adf910b9c31489cfca3f8c793fb7152cb215ebb1050abf53db9904e1a4b447b9c8b195bcfd9670d0159cf157c84c7336f5768b390248cc8b0be4d9dfb515163407'}, {'domain': '.x.com', 'expiry': 1773924257, 'httpOnly': True, 'name': 'auth_token', 'path': '/', 'sameSite': 'None', 'secure': True, 'value': '4b37f027aa860025c02899f572d0cb6994f2888f'}, {'domain': '.x.com', 'expiry': 1773937041, 'httpOnly': False, 'name': 'guest_id_ads', 'path': '/', 'sameSite': 'None', 'secure': True, 'value': 'v1%3A173937703239373590'}, {'domain': '.x.com', 'expiry': 1739386034, 'httpOnly': False, 'name': 'gt', 'path': '/', 'sameSite': 'Lax', 'secure': True, 'value': '1889710360883569053'}, {'domain': '.x.com', 'expiry': 1770913040, 'httpOnly': False, 'name': 'personalization_id', 'path': '/', 'sameSite': 'None', 'secure': True, 'value': '\"v1_W9ROGLWA5Y+O643Upc6zhA==\"'}, {'domain': '.x.com', 'expiry': 1773937041, 'httpOnly': False, 'name': 'guest_id_marketing', 'path': '/', 'sameSite': 'None', 'secure': True, 'value': 'v1%3A173937703239373590'}, {'domain': '.x.com', 'expiry': 1770913040, 'httpOnly': False, 'name': 'night_mode', 'path': '/', 'sameSite': 'None', 'secure': True, 'value': '2'}, {'domain': '.x.com', 'expiry': 1770913033, 'httpOnly': False, 'name': 'guest_id', 'path': '/', 'sameSite': 'None', 'secure': True, 'value': 'v1%3A173937703239373590'}]\n",
      "Found 3 tweets on this page.\n",
      "Found 7 tweets on this page.\n",
      "Found 7 tweets on this page.\n",
      "Found 7 tweets on this page.\n",
      "[{'User': 'FayeYoko Babebie Taiwan', 'Date': '2025-02-12T03:32:13.000Z', 'Content': \"FayeYoko Babebie Taiwan @FayeYokoGSTW · 12h We're No.1 on Taiwan's trending list too! Everyone Geng Mak!   SHINE ON FAYEYOKO TO 4E #พาฝ้ายโยโกะคืนให้4E GIF 165 1.3K 2K 57K\", 'Hashtags': '#พาฝ', 'Mentions': '@FayeYokoGSTW', 'Likes': '0', 'Retweets': '0', 'Replies': '0'}, {'User': 'Swathi Chowdary', 'Date': '2025-02-11T05:27:47.000Z', 'Content': \"Swathi Chowdary @swathi_ysj · Feb 11 Guys, repeat with me... let's start this trend   #BoycottLaila  Comment or retweet with the above #Hashtag #YSRCPSOCIALMEDIA #YSRCPSM   Don't mess with my leader  @ysjagan    100 Retweets Possible...? 51 866 1.9K 46K\", 'Hashtags': '#BoycottLaila, #Hashtag, #YSRCPSOCIALMEDIA, #YSRCPSM', 'Mentions': '@swathi_ysj, @ysjagan', 'Likes': '0', 'Retweets': '0', 'Replies': '0'}, {'User': 'F Y : im only here for fayeyoko', 'Date': '2025-02-12T02:13:28.000Z', 'Content': 'F Y : im only here for fayeyoko @Fayeyoko_4ever · 14h Parody account We trending #1 and #2 on thai keep it up babebies, fairybabe and Yobies, Dont stop using the hastag we can do this keep fighting for faye and yoko  SHINE ON FAYEYOKO TO 4E #พาฝ้ายโยโกะคืนให้4E 200 1.3K 1.9K 54K', 'Hashtags': '#1, #2, #พาฝ', 'Mentions': '@Fayeyoko_4ever', 'Likes': '0', 'Retweets': '0', 'Replies': '0'}, {'User': 'G | LOVE fill the BLANK', 'Date': '2025-02-12T01:39:43.000Z', 'Content': \"G | LOVE fill the BLANK @FayeYoko_2024 · 14h Parody account WOW, WE'RE CURRENTLY TRENDING AT 1ST AND 2ND SPOT IN THAILAND!   SHINE ON FAYEYOKO TO 4E #พาฝ้ายโยโกะคืนให้4E GIF 194 1.1K 1.8K 52K\", 'Hashtags': '#พาฝ', 'Mentions': '@FayeYoko_2024', 'Likes': '0', 'Retweets': '0', 'Replies': '0'}, {'User': 'Bhargav Reddy', 'Date': '2025-02-11T10:38:39.000Z', 'Content': 'Bhargav Reddy @mbrforjagan · Feb 11 Twitter  Trending #BoycottLaila  Instagram Trending #BoycottLaila  YouTube Trending #BoycottLaila 48 972 2.5K 28K', 'Hashtags': '#BoycottLaila, #BoycottLaila, #BoycottLaila', 'Mentions': '@mbrforjagan', 'Likes': '0', 'Retweets': '0', 'Replies': '0'}, {'User': 'Paula', 'Date': '2025-02-11T21:09:54.000Z', 'Content': 'Paula @minimoofarmlife · 19h F Trump is trending, that means liberals are crying again. GIF 80 61 927 82K', 'Hashtags': '', 'Mentions': '@minimoofarmlife', 'Likes': '0', 'Retweets': '0', 'Replies': '0'}, {'User': 'YS Jagan Fans Campaign™', 'Date': '2025-02-11T13:25:39.000Z', 'Content': 'YS Jagan Fans Campaign™ @YSJFansCampaign · Feb 11 200K+ Tweets on #BoycottLaila    First Ever Negative Trend in Recent times to create this Record   Never Ever Mess with  @ysjagan  fans ! 0:02 / 0:05 61 919 1.9K 25K', 'Hashtags': '#BoycottLaila', 'Mentions': '@YSJFansCampaign, @ysjagan', 'Likes': '0', 'Retweets': '0', 'Replies': '0'}, {'User': 'G | LOVE fill the BLANK', 'Date': '2025-02-12T02:06:22.000Z', 'Content': 'G | LOVE fill the BLANK @FayeYoko_2024 · 14h Parody account WORLDWIDE TRENDING AT NO. 1 AND 2!!! WE ARE SO POWERFUL! KEEP FIGHTING FOR FAYE AND YOKO!  SHINE ON FAYEYOKO TO 4E #พาฝ้ายโยโกะคืนให้4E GIF 167 1K 1.5K 40K', 'Hashtags': '#พาฝ', 'Mentions': '@FayeYoko_2024', 'Likes': '0', 'Retweets': '0', 'Replies': '0'}, {'User': 'Faye Malisorn USA', 'Date': '2025-02-12T08:55:20.000Z', 'Content': 'Faye Malisorn USA @FayeMalisornUSA · 7h For the warriors still trending in the USA/Canada & for those just waking up in Europe, here is the one and only Faye Peraya to give you the energy to keep going!  Like & Comment:  \"Put FayeYoko back in 4 Elements\"  SHINE ON FAYEYOKO TO 4E  #พาฝ้ายโยโกะคืนให้4E 101 523 744 7.8K', 'Hashtags': '#พาฝ', 'Mentions': '@FayeMalisornUSA', 'Likes': '0', 'Retweets': '0', 'Replies': '0'}, {'User': 'զor ʄąŋ', 'Date': '2025-02-12T03:02:46.000Z', 'Content': \"զor ʄąŋ @qoroth8 · 13h Look at all these countries trending our tags!  Special mention to Canada - this is the first time I've seen them in the mix! Great job.  SHINE ON FAYEYOKO TO 4E #พาฝ้ายโยโกะคืนให้4E 48 377 531 11K\", 'Hashtags': '#พาฝ', 'Mentions': '@qoroth8', 'Likes': '0', 'Retweets': '0', 'Replies': '0'}, {'User': 'G | LOVE fill the BLANK', 'Date': '2025-02-12T01:39:43.000Z', 'Content': \"G | LOVE fill the BLANK @FayeYoko_2024 · 14h Parody account WOW, WE'RE CURRENTLY TRENDING AT 1ST AND 2ND SPOT IN THAILAND!   SHINE ON FAYEYOKO TO 4E #พาฝ้ายโยโกะคืนให้4E GIF 194 1.1K 1.8K 52K\", 'Hashtags': '#พาฝ', 'Mentions': '@FayeYoko_2024', 'Likes': '0', 'Retweets': '0', 'Replies': '0'}, {'User': 'Bhargav Reddy', 'Date': '2025-02-11T10:38:39.000Z', 'Content': 'Bhargav Reddy @mbrforjagan · Feb 11 Twitter  Trending #BoycottLaila  Instagram Trending #BoycottLaila  YouTube Trending #BoycottLaila 48 972 2.5K 28K', 'Hashtags': '#BoycottLaila, #BoycottLaila, #BoycottLaila', 'Mentions': '@mbrforjagan', 'Likes': '0', 'Retweets': '0', 'Replies': '0'}, {'User': 'Paula', 'Date': '2025-02-11T21:09:54.000Z', 'Content': 'Paula @minimoofarmlife · 19h F Trump is trending, that means liberals are crying again. GIF 80 61 927 82K', 'Hashtags': '', 'Mentions': '@minimoofarmlife', 'Likes': '0', 'Retweets': '0', 'Replies': '0'}, {'User': 'YS Jagan Fans Campaign™', 'Date': '2025-02-11T13:25:39.000Z', 'Content': 'YS Jagan Fans Campaign™ @YSJFansCampaign · Feb 11 200K+ Tweets on #BoycottLaila    First Ever Negative Trend in Recent times to create this Record   Never Ever Mess with  @ysjagan  fans ! 0:02 / 0:05 61 919 1.9K 25K', 'Hashtags': '#BoycottLaila', 'Mentions': '@YSJFansCampaign, @ysjagan', 'Likes': '0', 'Retweets': '0', 'Replies': '0'}, {'User': 'G | LOVE fill the BLANK', 'Date': '2025-02-12T02:06:22.000Z', 'Content': 'G | LOVE fill the BLANK @FayeYoko_2024 · 14h Parody account WORLDWIDE TRENDING AT NO. 1 AND 2!!! WE ARE SO POWERFUL! KEEP FIGHTING FOR FAYE AND YOKO!  SHINE ON FAYEYOKO TO 4E #พาฝ้ายโยโกะคืนให้4E GIF 167 1K 1.5K 40K', 'Hashtags': '#พาฝ', 'Mentions': '@FayeYoko_2024', 'Likes': '0', 'Retweets': '0', 'Replies': '0'}, {'User': 'Faye Malisorn USA', 'Date': '2025-02-12T08:55:20.000Z', 'Content': 'Faye Malisorn USA @FayeMalisornUSA · 7h For the warriors still trending in the USA/Canada & for those just waking up in Europe, here is the one and only Faye Peraya to give you the energy to keep going!  Like & Comment:  \"Put FayeYoko back in 4 Elements\"  SHINE ON FAYEYOKO TO 4E  #พาฝ้ายโยโกะคืนให้4E 101 523 744 7.8K', 'Hashtags': '#พาฝ', 'Mentions': '@FayeMalisornUSA', 'Likes': '0', 'Retweets': '0', 'Replies': '0'}, {'User': 'զor ʄąŋ', 'Date': '2025-02-12T03:02:46.000Z', 'Content': \"զor ʄąŋ @qoroth8 · 13h Look at all these countries trending our tags!  Special mention to Canada - this is the first time I've seen them in the mix! Great job.  SHINE ON FAYEYOKO TO 4E #พาฝ้ายโยโกะคืนให้4E 48 377 531 11K\", 'Hashtags': '#พาฝ', 'Mentions': '@qoroth8', 'Likes': '0', 'Retweets': '0', 'Replies': '0'}, {'User': 'G | LOVE fill the BLANK', 'Date': '2025-02-12T01:39:43.000Z', 'Content': \"G | LOVE fill the BLANK @FayeYoko_2024 · 14h Parody account WOW, WE'RE CURRENTLY TRENDING AT 1ST AND 2ND SPOT IN THAILAND!   SHINE ON FAYEYOKO TO 4E #พาฝ้ายโยโกะคืนให้4E GIF 194 1.1K 1.8K 52K\", 'Hashtags': '#พาฝ', 'Mentions': '@FayeYoko_2024', 'Likes': '0', 'Retweets': '0', 'Replies': '0'}, {'User': 'Bhargav Reddy', 'Date': '2025-02-11T10:38:39.000Z', 'Content': 'Bhargav Reddy @mbrforjagan · Feb 11 Twitter  Trending #BoycottLaila  Instagram Trending #BoycottLaila  YouTube Trending #BoycottLaila 48 972 2.5K 28K', 'Hashtags': '#BoycottLaila, #BoycottLaila, #BoycottLaila', 'Mentions': '@mbrforjagan', 'Likes': '0', 'Retweets': '0', 'Replies': '0'}, {'User': 'Paula', 'Date': '2025-02-11T21:09:54.000Z', 'Content': 'Paula @minimoofarmlife · 19h F Trump is trending, that means liberals are crying again. GIF 80 61 927 82K', 'Hashtags': '', 'Mentions': '@minimoofarmlife', 'Likes': '0', 'Retweets': '0', 'Replies': '0'}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "\n",
    "def load_cookies(driver, cookie_file):\n",
    "    try:\n",
    "        with open(cookie_file, \"r\") as file:\n",
    "            cookies = json.load(file)\n",
    "            if not cookies:\n",
    "                print(\"⚠️ Cookie file is empty!\")\n",
    "                return\n",
    "            \n",
    "            for cookie in cookies:\n",
    "                # Convert ISO 8601 expiry to UNIX timestamp\n",
    "                if \"expiry\" in cookie:\n",
    "                    try:\n",
    "                        cookie[\"expiry\"] = int(datetime.strptime(cookie[\"expiry\"], \"%Y-%m-%dT%H:%M:%S.%fZ\").timestamp())\n",
    "                    except ValueError:\n",
    "                        print(f\"⚠️ Skipping cookie {cookie['name']} due to invalid expiry format: {cookie['expiry']}\")\n",
    "                        del cookie[\"expiry\"]  # Remove invalid expiry field\n",
    "                \n",
    "                driver.add_cookie(cookie)\n",
    "            print(\"✅ Cookies loaded successfully!\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"⚠️ Error: Invalid JSON format in the cookie file.\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error while loading cookies: {e}\")\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "import re\n",
    "\n",
    "def extract_tweet_data(tweet):\n",
    "    \"\"\"Extract detailed information from a tweet element.\"\"\"\n",
    "    try:\n",
    "        user = tweet.find_element(By.CSS_SELECTOR, 'div[dir=\"ltr\"] span').text\n",
    "    except:\n",
    "        user = \"Unknown\"\n",
    "\n",
    "    try:\n",
    "        content = tweet.text.replace(\"\\n\", \" \")\n",
    "    except:\n",
    "        content = \"\"\n",
    "\n",
    "    try:\n",
    "        date = tweet.find_element(By.CSS_SELECTOR, 'time').get_attribute(\"datetime\")\n",
    "    except:\n",
    "        date = \"Unknown\"\n",
    "\n",
    "    try:\n",
    "        likes = tweet.find_element(By.CSS_SELECTOR, 'div[data-testid=\"like\"]').text\n",
    "    except:\n",
    "        likes = \"0\"\n",
    "\n",
    "    try:\n",
    "        retweets = tweet.find_element(By.CSS_SELECTOR, 'div[data-testid=\"retweet\"]').text\n",
    "    except:\n",
    "        retweets = \"0\"\n",
    "\n",
    "    try:\n",
    "        replies = tweet.find_element(By.CSS_SELECTOR, 'div[data-testid=\"reply\"]').text\n",
    "    except:\n",
    "        replies = \"0\"\n",
    "\n",
    "    # Extract hashtags and mentions\n",
    "    hashtags = \", \".join(re.findall(r\"#\\w+\", content))\n",
    "    mentions = \", \".join(re.findall(r\"@\\w+\", content))\n",
    "\n",
    "    return {\n",
    "        \"User\": user,\n",
    "        \"Date\": date,\n",
    "        \"Content\": content,\n",
    "        \"Hashtags\": hashtags,\n",
    "        \"Mentions\": mentions,\n",
    "        \"Likes\": likes,\n",
    "        \"Retweets\": retweets,\n",
    "        \"Replies\": replies\n",
    "    }\n",
    "\n",
    "# Function to fetch trending tweets\n",
    "def fetch_trending_tweets(cookie_file=\"cookies.json\", max_tweets=20):\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/132.0.0.0 Safari/537.36\")\n",
    "    \n",
    "    driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=options)\n",
    "    driver.get(\"https://x.com/home\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Load cookies and refresh\n",
    "    load_cookies(driver, cookie_file)\n",
    "    driver.refresh()\n",
    "    time.sleep(5)\n",
    "\n",
    "    print(\"Current page title:\", driver.title)  # Debugging login state\n",
    "\n",
    "    # Verify if cookies are still valid\n",
    "    print(\"Final Cookies in Browser:\", driver.get_cookies())\n",
    "\n",
    "    # Go to trending page\n",
    "    driver.get(\"https://x.com/search?q=trending&src=trend_click\")\n",
    "    time.sleep(5)\n",
    "\n",
    "\n",
    "    tweet_data = []\n",
    "    tweet_count = 0\n",
    "\n",
    "    while tweet_count < max_tweets:\n",
    "        tweets = driver.find_elements(By.CSS_SELECTOR, 'article[data-testid=\"tweet\"]')\n",
    "        print(f\"Found {len(tweets)} tweets on this page.\")\n",
    "\n",
    "        for tweet in tweets:\n",
    "            data = extract_tweet_data(tweet)  # Extract structured tweet data\n",
    "            tweet_data.append(data)  # Append only the structured data\n",
    "            tweet_count += 1\n",
    "            if tweet_count >= max_tweets:\n",
    "                break\n",
    "\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)\n",
    "\n",
    "    driver.quit()\n",
    "    return tweet_data\n",
    "\n",
    "# Run the scraper\n",
    "tweets = fetch_trending_tweets()\n",
    "print(tweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 20 tweets saved to tweets.csv with structured data!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def save_tweets_to_csv(tweets, output_csv=\"tweets.csv\"):\n",
    "    if not tweets:\n",
    "        print(\"⚠️ No tweets to save!\")\n",
    "        return\n",
    "    \n",
    "    fieldnames = [\"User\", \"Date\", \"Content\", \"Hashtags\", \"Mentions\", \"Likes\", \"Retweets\", \"Replies\"]\n",
    "\n",
    "    with open(output_csv, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(tweets)\n",
    "\n",
    "    print(f\"✅ {len(tweets)} tweets saved to {output_csv} with structured data!\")\n",
    "\n",
    "# Save the structured tweets\n",
    "save_tweets_to_csv(tweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "trusted": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
